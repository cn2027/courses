---
title: Coursera: Practical Machine Learning Project - Quantified-Self Movement
  Report
author: "by CN2027""
output:
  html_document:
    fig_height: 8
    fig_width: 8
---

## Introduction  
It is now relatively in easy and expensive to collect data regarding ones activity and performance with the use of Jawbone Up, Nike FuelBand, and Fitbit monitoring devices. These type of devices are part of Quantified Self - movement, whereby a group of enthusiasts take measurements of themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. In this project, we will use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did the exercise. The goal is to look at how well well quantified activities are performed.

## Data Preprocessing  
```{r, cache = T}
pkgTest <- function(x)
{
  if (!require(x,character.only = TRUE))
  {
    install.packages(x,dep=TRUE)
    if(!require(x,character.only = TRUE)) stop("Package not found")
  }
}

pkgTest("caret");pkgTest("randomForest");pkgTest("corrplot");pkgTest("rpart");
pkgTest("ggplot2");pkgTest("gridExtra");pkgTest("reshape");pkgTest("gplots");
pkgTest("corrplot");pkgTest("rpart.plot")
```
### Download and Read Data
```{r, cache = T}
training.url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test.url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
path <- getwd()
download.file(training.url, destfile=paste(path,"pml_Train",sep="/"), method="curl")
download.file(test.url, destfile=paste(path,"pml_Test",sep="/"), method="curl")
training <- read.csv("pml_Train");test <- read.csv("pml_Test")
dim(training);dim(test) 
```  
Our goal is to predict the "classe" variable. The training and test sets contain the same number of variables (160). However, the training set contains 19622 observations while the test set contains 20 observations. 

### Clean Data
We will clean the data: delete missing values and delete useless variables.
```{r, cache = T}
classe.training<-training$classe
clean.train <- training[,c(-1,-3,-4,-5,-6,-7)] #timestamp variables and and window are not necessary
clean.test <- test[,c(-1,-3,-4,-5,-6,-7)]
clean.train <- clean.train[, colSums(is.na(clean.train)) == 0];dim(clean.train) #Deletes columns with missing (NA) values
clean.test <- clean.test[, colSums(is.na(clean.test)) == 0];dim(clean.test)
clean.train<-clean.train[,sapply(clean.train,is.numeric)];dim(clean.train)
clean.test<-clean.test[,sapply(clean.test,is.numeric)];dim(clean.test)
clean.train <- clean.train[,colnames(clean.train) %in% colnames(clean.test)];dim(clean.train)
clean.train$classe<-classe.training;dim(clean.train)
```  
The clean training and test sets now contain 53 variables instead of 160.

### Split Data
We will split the clean training set into 70:30 training to validation sets. The validation set will be utilized to perform cross validation.  
```{r, cache = T}
set.seed(3433) # For reproducibile purpose
inTrain <- createDataPartition(clean.train$classe, p=3/4, list=FALSE)
train <- clean.train[inTrain, ];testing <- clean.train[-inTrain, ]
```

### Model Data
We fit a predictive model for activity recognition using Random Forest  and use 5-fold cross validation.  
```{r, cache = T}
trainRF <- trainControl(method="cv", 5)
model.trainRF <- train(classe ~ ., data=train, method="rf", trControl=trainRF, ntree=30)
model.trainRF

predictRF <- predict(model.trainRF, testing);confusionMatrix(testing$classe, predictRF)

accuracy <- postResample(predictRF, testing$classe);accuracy
sample.error <- 1 - as.numeric(confusionMatrix(testing$classe, predictRF)$overall[1]);sample.error
```
The estimated model accuracy is 96.39% and the estimated out-of-sample error is 3.6%.

## Predict for Original Test Data
Now, we apply the model to the original testing data set downloaded from the data source. We remove the `problem_id` column first.  
```{r, cache = T}
predictTest <- predict(model.trainRF, clean.test[, -length(names(clean.test))]);
predictTest
```  

### Appendix: Figures
Decision Tree
```{r, cache = T}
Tree <- rpart(classe ~ ., data=clean.train, method="class")
prp(Tree) # Tree model
```
